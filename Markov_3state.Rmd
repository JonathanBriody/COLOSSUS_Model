---
title: 'Exploratory Cost-Effectiveness Analysis of HDX Assayased on New Diagnostic Tests vs Standard of Care in Microsatellite Stable RAS Mutant Metastatic Colorectal Cancer Patients'
author: "Jonathan Briody (1) | Kathleen Bennett (1)"
output:
  html_document: default
  pdf_document: default
editor_options: 
  markdown: 
    wrap: sentence
bibliography: references.bib
---

(1) Data Science Centre, RCSI University of Medicine and Health Sciences, Dublin, Ireland

**Correspondence:**

Jonathan Briody, PhD, RCSI University of Medicine and Health Sciences, Beaux Lane House, Lower Mercer St, Dublin 2, Ireland.
Email: [jonathanbriody\@rcsi.ie](mailto:jonathanbriody@rcsi.ie){.email}

**Funding Information:**

This project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 754923.
The material presented and views expressed here are the responsibility of the author(s) only.
The EU Commission takes no responsibility for any use made of the information set out.

\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, eval = T)
# To knit this document every time it is run, you can change `eval` to `TRUE` in the above.
```

```{r}
rm(list = ls())  
# clear memory (removes all the variables from the work space)
```

# 01 Load packages

```{r}
if (!require('pacman')) install.packages('pacman'); library(pacman) 
# use this package to conveniently install other packages
# load (install if required) packages from CRAN
p_load("diagram", "dampack", "reshape2")
# library(devtools) # devtools is necessary to install from github.
# install_github("DARTH-git/darthtools", force = TRUE) # Uncomment if there is a newer version
p_load_gh("DARTH-git/darthtools")
```

# 02 Load functions

```{r}
# all functions are in the darthtools package

# There is a functions RMD for the PSA stuff below, instead of calling it in: ## 08.2 Load PFS-PFSer Markov model function, I could just place it here, and place all the necessary packages above and then I would only ever need 1 R Markdown document for the entire study. Will think about doing this.


```

# To use dampack, review this before you start:

<https://cran.r-project.org/web/packages/dampack/vignettes/basic_cea.html>

<https://cran.r-project.org/web/packages/dampack/vignettes/dsa_generation.html>

<https://cran.r-project.org/web/packages/dampack/vignettes/psa_generation.html>

<https://cran.r-project.org/web/packages/dampack/vignettes/psa_analysis.html>

<https://cran.r-project.org/web/packages/dampack/vignettes/voi.html>

<https://cran.r-project.org/web/packages/dampack/dampack.pdf>

also saved as pdf files here:

C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\R Code\GitHub\COLOSSUS\_Model

The dampack package was based on the following textbook:

[file:///C:/Users/Jonathan/OneDrive%20-%20Royal%20College%20of%20Surgeons%20in%20Ireland/COLOSSUS/R%20Code/GitHub/COLOSSUS_Model/(Cambridge%20medicine)%20Hunink,%20M.%20G.%20Myriam_Weinstein,%20Milton%20C%20-%20Decision%20making%20in%20health%20and%20medicine\_%20integrating%20evidence%20and%20values.pdf](file:///C:/Users/Jonathan/OneDrive%20-%20Royal%20College%20of%20Surgeons%20in%20Ireland/COLOSSUS/R%20Code/GitHub/COLOSSUS_Model/(Cambridge%20medicine)%20Hunink,%20M.%20G.%20Myriam_Weinstein,%20Milton%20C%20-%20Decision%20making%20in%20health%20and%20medicine_%20integrating%20evidence%20and%20values.pdf)

If I find any parts of the package confusing I can email:

Maintainer: Greg Knowlton \<knowl193\@umn.edu\>

The official website is here: <https://cran.r-project.org/web/packages/dampack/>

# 03 Input model parameters

```{r}
## General setup
# Here we define all our model parameters, so that we can call on these parameters later during our model:

n_cycles        <- 60                            
# We set the number of cycles to 60 to reflect 5 years broken down into monthly cycles
v_names_cycles  <- paste("cycle", 0:n_cycles)    
# So here, we just name each cycle by the cycle its on, going from o up to the number of cycles there are, here 60.
v_names_states  <- c("PFS", "OS", "Dead")  
# These are the health states in our model, PFS, OS, Death.
n_states        <- length(v_names_states)        
# We're just taking the number of health states from the number of names we came up with, i.e. 3 names to reflect three health states 

# Strategy names
v_names_str     <- c("Standard of Care",         
                     "EPI Assay", ## AKA Treatment A
                     "HDX Assay") ## AKA Treatment B 
# store the strategy names
n_str           <- length(v_names_str)           
# number of strategies


## Transition probabilities


# "Note: To calculate the probability of dying from S1 and S2, use the hazard ratios provided. To do so, first convert the probability of dying from healthy, p_HD , to a rate; then multiply this rate by the appropriate hazard ratio; finally, convert this rate back to a probability. Recall that you can convert between rates and probabilities using the following formulas: r = − log(1 − p) and p = 1 − e ( − rt ) . The package darthtools also has the functions prob_to_rate and rate_to_prob that might be of use to you." per: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop _ DARTH\August_25\3_cSTM - history dependence_material\Download exercise handout 

# ?rate_to_prob will tell you more about this function.
# ?prob_to_rate will tell you more about this function.

# As will the 50 minute mark of: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop _ DARTH\August_25\Live Session Recording\Live Session Recording August 25th WITH CHAT.mkv


# The above also describes how to convert probabilities for different time scales, i.e., convert a probability for 5 years to 1 year, etc., and how to convert data that exists as a rate to a probability for use in a Markov model.


p_HS_SoC  <- 0.05  # probability of becoming OS when PFS, conditional on surviving, under standard of care
p_HS_trtA <- 0.04  # probability of becoming OS when PFS, conditional on surviving, under EPI Assay
p_HS_trtB <- 0.02  # probability of becoming OS when PFS, conditional on surviving, under HDX Assay
p_SD      <- 0.1   # probability of dying          
p_HD      <- 0.01  # probability of dying when PFS

# I'M NOT DELIGHTED ABOUT USING CONDITIONAL PROBABILITIES ACTUALLY, AND WILL UPDATE THE ABOVE WITH THE WAY I CALCULATED PROBABILITIES WHEN DOING THE YORK COURSE I THINK.

# That will mean that when I'm on the section below:

# Fill in the transition probability matrix:

# I'll have to change how these probabilities are filled in.


# H = HEALTHY (PFS) -> HS MEANS HEALTHY TO SICK, HD -> MEANS HEALTHY TO DEAD.
# S = SICK (OS) -> SD MEANS SICK TO DEAD.
# D = DEAD (DEAD) 

# trtA -> Means the first intervention I am studying, i.e. treatment A or the first assay.
# trtB -> Means the second intervention I am studying, i.e. treatment B or the second assay.

# To add age specific mortality to our model, we would use this #03 input model parameters of:

# "C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Decision Modeling for Public Health_DARTH\5_Nov_29\4_Cohort state-transition models (cSTM) - time-dependent models_material\Markov_3state_time"

# with the 55 minute mark of: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop _ DARTH\August_24\Live Session Recording\Live Session Recording August 24th.mp4

# and this would allow us to create a vector of transition probabilities for p_HD above, i.e., from PFS to dead, that is a little bit larger at each cycle, starting at our chosen minimum value at the first cycle and increasing each cycle until it reaches our chosen maximum value at the last cycle.

# Alternatively, C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop _ DARTH\August_24\4_cSTM - time-dependent models_material shows you how to use a life-table, as does the material from the York course, but I really think there's no need to get that detailed in our own analysis.




## Health State Values (AKA State rewards)
# Costs and utilities  
# Basically the outcomes we are interested in coming out of this model, so we'll look at the cohorts costs over the time horizon and the quality adjusted life years in our cohort over this time horizon.

c_H       <- 400   # cost of one cycle in PFS state
c_S       <- 1000  # cost of one cycle in OS state
c_D       <- 0     # cost of one cycle in dead state

# Above is the cost for each state, PFS, OS and dead,

c_trtA    <- 800   # cost of EPI Assay (per cycle) in PFS state
c_trtB    <- 1500  # cost of HDX Assay (per cycle) in PFS state

# We make the cost of EPI Assaybove so that when we have treatment strategies we can add this cost of treatment to anyone whose being treated when they receive the treatment.

u_H       <- 1     # utility when PFS 
u_S       <- 0.5   # utility when OS
u_D       <- 0     # utility when dead

# Then we define the utilities per health states.


# Discounting factors
d_c             <- 0.03                          
# discount rate for costs
d_e             <- 0.03                          
# discount rate for QALYs

# discount rate per cycle equal discount of costs and QALYs by 3%

# Discount weight (equal discounting is assumed for costs and effects)
v_dwc <- 1 / (1 + d_c) ^ (0:n_cycles) 
v_dwe <- 1 / (1 + d_e) ^ (0:n_cycles) 

# So, we create a discount weight vector above, to understand the way this works I'll have to return to my York notes on discounting


```

Discount rate for costs and utilities I've set as 3% here, I need to return to this and set it as 4%.
I also need to return to it more generally with the notes I wrote from York on discounting.
Also I set up 3 strategies, i.e. standard of care, EPI Assay and HDX Assay, to reflect the two assays under study, but it would be very easy to change this to just 2 strategies above.

I also want to add in the costing per the York model, as this broke costs down before adding them, although I can compare this to the York approach to costing in their published article, i.e. are costs in that article combined before they are added to the model or afterwards?

There are some things that I would like to appear in the code chunks, but not in the knitted document.
To do this I can go to:

<https://stackoverflow.com/questions/47710427/how-to-show-code-but-hide-output-in-rmarkdown>

and

<https://stackoverflow.com/questions/48286722/rmarkdown-how-to-show-partial-output-from-chunk?rq=1>

Although I can probably just use:

knitr::opts_chunk\$set(echo = TRUE, warning = FALSE, message = FALSE, eval = T)

But set echo = false

Or even better, click the gear on each code chunk and decide if I would like that code chunk to show things or not.

If I was interested in how to add adverse events to the model, Eva describes how to create an additional state that is Sick+AdverseEvent here:

C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop \_ DARTH\August\_25\Live Session Recording\Live Session Recording August 25th WITH CHAT.mkv

## Draw the state-transition cohort model

```{r}
m_P_diag <- matrix(0, nrow = n_states, ncol = n_states, dimnames = list(v_names_states, v_names_states))
m_P_diag["PFS", "OS" ]     = "" 
m_P_diag["PFS", "Dead" ]     = ""
m_P_diag["PFS", "PFS" ]  = ""
m_P_diag["OS"   , "Dead" ]     = ""
m_P_diag["OS"   , "OS" ]     = ""
m_P_diag["Dead"   , "Dead" ]     = ""
layout.fig <- c(2, 1)
plotmat(t(m_P_diag), t(layout.fig), self.cex = 0.5, curve = 0, arr.pos = 0.8,  
        latex = T, arr.type = "curved", relsize = 0.85, box.prop = 0.8, 
        cex = 0.8, box.cex = 0.7, lwd = 1)
```

# 04 Define and initialize matrices and vectors

After setting up our parameters above, we initialise our structure below.

This is where we will store all of the model output, and all the things that we need to track over time as we are simulating the progression of this cohort through this disease process.

## 04.1 Cohort trace

```{r}
## Initial state vector
# We create an inital vector where people start, with everyone (1 = 100% of people) starting in PFS below:
v_s_init <- c("PFS" = 1, "OS" = 0, "Dead" = 0)  
v_s_init

# There are cases where you can have an initial illness prevalence, so you would start some people in the sick state and some people in the healthy state, but above we're looking at people with mCRC, so we'll start everyone in PFS.



## Initialize cohort trace for cSTM (cohort state transition model) for all strategies (the strategies are the treatment strategies SOC, treatment A and Treatment B).
# So, basically we are creating a matrix to trace how the cohort is distributed across the health states, over time. 

# A matrix is necessary because there are basically two dimensions to this, the number of time cycles, which will be our rows, and then the number of states - to know which proportion of our cohort is in each state at each time:

m_M_SoC <- matrix(0, 
                  nrow = (n_cycles + 1), ncol = n_states, 
                  dimnames = list(v_names_cycles, v_names_states))
# Store the initial state vector in the first row of the cohort trace
m_M_SoC[1, ] <- v_s_init
## Initialize cohort traces
## So, above I made the cohort trace for standard of care, because in my analysis all my patients start in the PFS state, I can duplicate that below to create the cohort trace for treatment A and treatment B.
m_M_trtA <- m_M_trtB <- m_M_SoC # structure and initial states remain the same

# This gives us three matrices, m_M_trtA, m_M_trtB and m_M_SoC, that we can fill in with out simulations of how patients transitions between health states under each treatment strategy.

```

## 04.2 Transition probability matrix

```{r}

## If there were time varying transition probabilities, i.e. the longer you are in the model there are changes in your transition probability into death as you get older, etc., you would build a transition probability array, rather than a transition probability matrix, per: 

# 04.2 of:

# "C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Decision Modeling for Public Health_DARTH\5_Nov_29\4_Cohort state-transition models (cSTM) - time-dependent models_material\Markov_3state_time"

# with the 1hour: 02minute mark of: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop _ DARTH\August_24\Live Session Recording\Live Session Recording August 24th.mp4


## Initialize transition probability matrix, [i.e. build the framework or empty scaffolding of the transition probability matrix]
# all transitions to a non-death state are assumed to be conditional on survival 
m_P_SoC  <- matrix(0,
                   nrow = n_states, ncol = n_states,
                   dimnames = list(v_names_states, v_names_states)) # define row and column names
m_P_SoC
```

Fill in the transition probability matrix:

```{r}
## Standard of Care
# from PFS
m_P_SoC["PFS", "PFS"] <- (1 - p_HD) * (1 - p_HS_SoC)

# It's 1- p_HD, because if you're not going from healthy to dead then you're staying in healthy (i.e. you're not going from PFS to Dead, so you're staying in PFS) so this captures all the people leftover in PFS after those going to dead, and again for 1- p_HS_SoC, if you're not going from healthy to sick, the only other way out of healthy per the transition probability matrix, then you're staying in PFS, so 1- p_HS_SoC takes away all the people who went from healthy to sick, and leaves behind all the people who stayed in healthy (or takes away all the people who went to OS and leaves behind all the people that went to PFS per my model).

m_P_SoC["PFS", "OS"]    <- (1 - p_HD) *      p_HS_SoC

# This is because, when setting up the input parameters we didn't have a value for staying in progression free survival, so we have to calculate it, i.e. above we have to get the probability for going from PFS to OS, by getting all the people left in PFS after the people who went to death were gone, and then we multiply this probability by the probability of going from healthy to sick, or PFS to OS, because it's the probability conditional on being alive, the probability conditional on being left in the PFS state after the other people who went to the death state are gone, so the probability of going from PFS to OS, conditional on surviving.



# m_P_SoC["PFS", "OS"]    <- (1 - p_HD) *      p_HS_SoC

# p_HS_SoC is the probability of transitioning from healthy to sick, conditional on surviving, so it's defined as a conditional probability. So, what the Markov model wants is : m_P_SoC["PFS", "OS"] what's the overall probability of transitioning from PFS to OS, and so that is actually not a conditional probability, which is why we multiply the probability of surviving (1 - p_HD) *      p_HS_SoC by the probability of going to OS conditional on surviving, because the transition in the model should be the marginal not the conditional, i.e. you want to have the end probability.





m_P_SoC["PFS", "Dead"]    <-      p_HD

# Your probability of going from healthy to dead is not conditional on surviving, per the input parameters section.


# from OS
m_P_SoC["OS", "OS"] <- 1 - p_SD
m_P_SoC["OS", "Dead"] <-     p_SD

# Per the input parameters, your probability of going from sick to dead is also not conditional on surviving, so we dont need to multiply our probability conditional on surviving by the number of survivors as above.

# That's why though, our PFS to OS probability calculated through multiplication above is so close to the 0.05 in the input parameters, i.e. it's 0.0495, because we multiply it by 1 - p_HD or 1-0.01, which is basically multiplying it by a number very close to 1, so the probability remains very close to where it started off. The probability is conditional on the numbers of people in the alive state, we calculate that to be nearly 100% of people, so the probability remains the same. 


# m_P_SoC["PFS", "PFS"] <- (1 - p_HD) * (1 - p_HS_SoC)
# And the first one (commented out above) is the same, it's the probability of going from healthy to healthy which, because it's a conditional probability, is the number of individuals left in healthy multiplied by the probability of going from healthy to health conditional on surviving to be in healthy (so, to get a conditional probability we multiply the numbers who have survived by the probability -> here we don't have a probability for healthy to healthy, but we do have a probability for health to sick, so taking 1 - this gives us the probability of not going into sick, i.e. of staying in healthy instead). 

# from Dead
m_P_SoC["Dead", "Dead"] <- 1

# Once you're in dead you stay in dead, you can't come back to life.


# For handiness, we just take the treatment matrix that already exists for standard of care above, copy it as treatment A and treatment B, and then copy over it with new values specific to treatment A and treatment B, assuming that the probability of going from PFS to dead and staying in OS and going from OS to dead are the same as for standard of care (dead to dead is definitely the same as no one leaves dead) that's likely a reasonable assumption for our model, as once people progress we can assume they all go on to the same next treatment, standard of care progression treatment with the same likelihood of staying in OS and of going to the dead state, regardless of the novel therapy they were on:

## EPI Assay
m_P_trtA <- m_P_SoC
m_P_trtA["PFS", "PFS"] <- (1 - p_HD) * (1 - p_HS_trtA)
m_P_trtA["PFS", "OS"]    <- (1 - p_HD) *      p_HS_trtA

## HDX Assay
m_P_trtB <- m_P_SoC
m_P_trtB["PFS", "PFS"] <- (1 - p_HD) * (1 - p_HS_trtB)
m_P_trtB["PFS", "OS"]    <- (1 - p_HD) *      p_HS_trtB



# You can also think of it, per the 1hour: 05minute mark of: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop _ DARTH\August_24\Live Session Recording\Live Session Recording August 24th.mp4


# m_P_SoC["PFS", "OS"]    <- (1 - p_HD) [<- if you don't die] *      p_HS_SoC [then you have a risk of getting sick]

# It wont always be necessary to do this, i.e., to include conditional probabilities, it will depend on the data used and how things were estimated.

# This approach is taken for conditional probabilities, it's probably more relevant for modelling people to really, really old ages, where their mortality gets really high (so this is particularly relevant when you have age specific mortality), where you still have this high mortality of getting sick, you can end up in problems with the probabilities where the probability of leaving the state gets too high, because you haven't properly adjusted for these really high mortality rates, as people get really old.

# So, what this is doing is saying, if you don't die, then it's the remaining people who experience the probability of getting sick, so you're not adding probabilities together, which can be problematic, because sometimes you can have probabilities come to greater than one (i.e., larger than 100%).

# It's always worth considering, if you're extrapolating this risk of illness that's pretty high, on top of a cohort that also has a high risk of death, maybe that's not the right extrapolation, but this is another kind of fail safe to avoid that.

# Depending on how the data is estimated, this a correct interpretation of the probability estimate of going from one state to another (p_HS_SoC, or healthy to sick, or PFS to OS). 


# Using conditional probabilities more generally is also discussed around the 1:04 hour mark of:

# C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop \_ DARTH\August\_25\Live Session Recording\Live Session Recording August 25th WITH CHAT.mkv



```

I probably want to get rid of the conditional probabilities above, replacing them with standard transition probabilities per my York training.

Check if transition probability matrices are valid.

```{r}
# This is a check in the DARTH tools package that all the transition probabilities are in [0, 1], i.e., no probabilities are greater than 100%.
check_transition_probability(m_P_SoC,  verbose = TRUE)
check_transition_probability(m_P_trtA, verbose = TRUE)
check_transition_probability(m_P_trtB, verbose = TRUE)
# Check that all rows sum in each matrix sum to 1 -> which we know is a necessary condition for transition probability matrices.
check_sum_of_transition_array(m_P_SoC,  n_states = n_states, verbose = TRUE)
check_sum_of_transition_array(m_P_trtA, n_states = n_states, verbose = TRUE)
check_sum_of_transition_array(m_P_trtB, n_states = n_states, verbose = TRUE)
```

# 05 Run Markov model

```{r}
for (t in 1:n_cycles){  # Use a for loop to loop through the number of cycles, basically we'll calculate the cohort distribution at the next cycle [t+1] based on the matrix of where they were at time t, matrix multiplied by the transition probability matrix for the current cycle (constant for us as we use a constant transition probability matrix, rather than a transition probability array).
# We do this for each treatment, as they all have different transition probability matrices. 
  m_M_SoC [t + 1, ] <- m_M_SoC [t, ] %*% m_P_SoC   # estimate the state vector for the next cycle (t + 1)
  m_M_trtA[t + 1, ] <- m_M_trtA[t, ] %*% m_P_trtA  # estimate the state vector for the next cycle (t + 1)
  m_M_trtB[t + 1, ] <- m_M_trtB[t, ] %*% m_P_trtB  # estimate the state vector for the next cycle (t + 1)
}
head(m_M_SoC)  # print the first few lines of the matrix for standard of care (m_M_SoC)
```

# 06 Compute and Plot Epidemiological Outcomes

## 06.1 Cohort trace

```{r}

# So, we'll plot the above Markov model for standard of care (m_M_SoC) to show our cohort distribution over time, i.e. the proportion of our cohort in the different health states over time.

# If I wanted to do the same for Treatment A and Treatment B, I would just copy this code chunk and replace m_M_SoC with m_M_trtA and m_M_trtB

matplot(m_M_SoC, type = 'l', 
        ylab = "Probability of state occupancy",
        xlab = "Cycle",
        main = "Cohort Trace", lwd = 3)  # create a plot of the data
legend("right", v_names_states, col = c("black", "red", "green"), 
       lty = 1:3, bty = "n")  # add a legend to the graph

# plot a vertical line that helps identifying at which cycle the prevalence of OS is highest
abline(v = which.max(m_M_SoC[, "OS"]), col = "gray")
# The vertical line shows you when your sick (OS) population is the greatest that it will ever be, but it can be changed from which.max to other things (so it is finding which cycle the proportion sick is the highest and putting a vertical line there).



# So, you can see in the graph everyone starts in the PFS state, but that this falls over time as people progress and leave this state, then you see OS start to peak up but then fall again as people leave this state to go into the dead state, which is an absorbing state and by the end will include everyone.

```

## 06.2 Overall Survival (OS)

Although in the context of my analysis this would be PFS + OS because it is drawn from the DARTH model where healthy and sick make up OS, while dead means not OS (obviously).

```{r}
v_os <- 1 - m_M_SoC[, "Dead"]    # calculate the overall survival (OS) probability
v_os <- rowSums(m_M_SoC[, 1:2])  # alternative way of calculating the OS probability

# I could do my own version of this and chose just to look at pfs, rather than column 1 and 2 to look at anyone not dead.

# i.e. v_os <- (m_M_SoC[, 1])

# best practice would be to rename v_os if I am looking at something that isnt os, i.e. v_pfs and to of course update the table legend, bearing in mind that yet again this is all for standard of care, and that if I wanted to know this for treatment a and/or treatment b I would need to replace the Markov model matrix above.


plot(v_os, type = 'l', 
     ylim = c(0, 1),
     ylab = "Survival probability",
     xlab = "Cycle",
     main = "Overall Survival")  # create a simple plot showing the OS

# add grid 
grid(nx = n_cycles, ny = 10, col = "lightgray", lty = "dotted", lwd = par("lwd"), 
     equilogs = TRUE) 


# Per 1:12 hour mark of: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop \_ DARTH\August\_25\Live Session Recording\Live Session Recording August 25th WITH CHAT.mkv

# Often you have a survival curve as input to your model [I guess from a published study], and having that survival curve you need to parameterise your model so that you match that survival curve, and that would be a process of, potentially of calibration, if you can't use the parameters directly in your model.

# So, you could produce your survival curve and compare it to curves from trials, etc., to calibrate your model. So. we'll probably do this and have it in an appendix section.

# For calibration purposes, you want to make sure that your model is outputting something that's comparable to the publications out there on actual data on the same type of patients.

# Part of being comparable to the real world is that if there is a censoring process in actual patient data, then you could incorporate this process into the model to reflect that in your model and to ensure that your own model is comparable to the existing models which may be losing people due to censoring, etc., and which you'll then need to incorporate into your model to be comparable. 


# Another interesting thing you can do is, plot this to ask is that reasonable, does that make sense that this many people are alive after this amount of time? Is the OS what I would expect it to be?


```

## 06.2.1 Life Expectancy (LE)

```{r}
v_le <- sum(v_os)  # summing probability of OS over time  (i.e. life expectancy)

# Basically we are summing all the alive states over time through over all the cycles, so 

# v_os <- rowSums(m_M_SoC[, 1:2])

# Is basically the PFS and OS added together.

# Also bear in mind that this is life expectancy under standard of care, and not under either of the new treatments, per: # v_os <- rowSums(m_M_SoC[, 1:2]) above.

v_le


# So, this gives a value of [1] 24.26038, that is [1] 24.26038 cycles, where in the context of our model, cycles are months, so the life expectancy for our population of patients is 24 months.


# Discounted life expectancy:

# If you wanted discounted life expectancy, if you were using life years and you wanted them discounted for your health economic outcomes, you could apply the discount rates - the discount factors - to the vector for overall survival [v_os] and then take it's sum [add it up] as above to get life expectancy that is discounted.

# As the 1:12 hour mark of: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop _ DARTH\August_25\Live Session Recording\Live Session Recording August 25th WITH CHAT.mkv



```

## 06.3 Disease prevalence

```{r}

# Disease prevalence is the proportion who are sick divided by the proportion who are alive, so it's necessary to account for the fact that some of the cohort have died, so you only calculate prevalence among people who are alive,in the diagram you can see it plateauing over time, even though the number of people in the OS (or "progressed") state have gone up and come down over time and this is because this is prevalence as a proportion of those who are alive, and there are few people who are still alive by cycle 60.

# Probably looks a bit funny dividing OS by v_os below, but it's necessary to remember that v_os is PFS + OS.

# So, I guess in our context you can think of this as progression prevalence over time:

v_prev <- m_M_SoC[, "OS"]/v_os
plot(v_prev,
     ylim = c(0, 1),
     ylab = "Prevalence",
     xlab = "Cycle",
     main = "Disease prevalence")
```

# 07 Compute Cost-Effectiveness Outcomes

## 07.1 Mean Costs and QALYs for each strategy

```{r}
# per cycle
# calculate expected costs by multiplying cohort trace with the cost vector for the different health states

# Basically, you take the cohort trace over time for each strategy [m_M_SoC] and multiply this by a vector of our costs for each state: [c(c_H, c_S, c_D)] -> So, basically the number of people in each state at each cycle multiplied by the cost of being in that state [cost of healthy, cost of sick and cost of dead] for each strategy that we look at (standard of care, treatment A and treatment B).

# Bear in mind we are doing matrix multiplication [%*%], because what this does is for each cycle [row in the matrix], take the vector of costs, and multiply it be the distribution in that cycle [breakdown of proportions in the states in that row] and add it all together, to get the total costs for that cycle [row]. This gives us a vector of the costs accrued in this cohort of individuals ending up in these different states for each cycle on a per person basis, because it's a cohort distribution (it always sums to 1).

# So, in cycle 1 everyone is in the OS state, so they only incur the OS cost, as more and more time passes and more and more people get sick, the costs increases due to more people being in the PFS state, but over time this falls again as more and more people go into the dead state, which has no costs as we don't treat corpses.

v_tc_SoC  <- m_M_SoC  %*% c(c_H, c_S, c_D)  
v_tc_trtA <- m_M_trtA %*% c(c_H + c_trtA, c_S, c_D)  
v_tc_trtB <- m_M_trtB %*% c(c_H + c_trtB, c_S, c_D)  

# calculate expected QALYs by multiplying cohort trace with the utilities for the different health states 

# The three vectors of utilities are basically built in the exact same way as the three vectors of costs above:

v_tu_SoC  <- m_M_SoC  %*% c(u_H, u_S, u_D)  
v_tu_trtA <- m_M_trtA %*% c(u_H, u_S, u_D) 
v_tu_trtB <- m_M_trtB %*% c(u_H, u_S, u_D) 

# These are quality adjusted cycles, these are quality adjusted life years where cycles are annual, so I need to consider what this means for utility where cycles are monthly... I suppose it's just quality adjusted monthly utility.

# You can see above that there are no utility differences between the different treatments considered: c(u_H, u_S, u_D), it's just different utilities per the health states people are in.

# If we did want to do different utilities for the health state you are in per the treatment you are on, we could define this in the input parameters and then add this in above when creating the vector of utilities for that treatment.


```

```{r}

# There's probably a more elegant way to do this, but if I wanted to add in the once off cost of the COSLOSSUS test, I could do something like the below:

# v_tc_trtA <-  v_tc_trtA+10
# v_tc_trtB <-  v_tc_trtB+100

# I just need to think about this and does it make sense, because it's adding to the cost each cycle, so probably the best indicator would be whether the cost outputted in 07.2 is only higher by the cost of the test when we do this, or if it is higher by a number of other costs, so I can check that below when adding costs in.


```

## 07.2 Discounted Mean Costs and QALYs

```{r}

# Finally, we'll aggregate these costs and utilities into overall discounted mean (average) costs and utilities.

# So, we take the vector of costs, transposing it [the t() bit] to make it a 1 row matrix and using matrix multiplication [%*%] to multiply it by that discount factor vector, which is what you multiply by the outcome in each cycle to get the discounted value of the outcome for that cycle, and then it will all be summed all together across all cycles [across all cells of the 1 row matrix]. Giving you tc_d_SoC which is a scalar, or a single value, which is the lifetime expected cost for an average person under standard of care in this cohort. 


# Discount costs by multiplying the cost vector with discount weights (v_dwc) 
tc_d_SoC  <-  t(v_tc_SoC)  %*% v_dwc
tc_d_trtA <-  t(v_tc_trtA) %*% v_dwc
tc_d_trtB <-  t(v_tc_trtB) %*% v_dwc


# So, now we have the average cost per person for treatment with standard of care, treatment A and treatment B. 


# Discount QALYS by multiplying the QALYs vector with discount weights (v_dwe) [probably utilities would be a better term here, as it's monthly health state quality of life, rather than yearly health state quality of life]
tu_d_SoC  <-  t(v_tu_SoC)  %*% v_dwe
tu_d_trtA <-  t(v_tu_trtA) %*% v_dwe
tu_d_trtB <-  t(v_tu_trtB) %*% v_dwe

# Store them into a vector -> So, we'll take the single values for cost for an average person under standard of care, treatment A and treatment B, and stored them in a vector v_tc_d
v_tc_d <- c(tc_d_SoC, tc_d_trtA, tc_d_trtB)
v_tu_d <- c(tu_d_SoC, tu_d_trtA, tu_d_trtB)

v_tc_d
v_tu_d

# To make things a little easier to read we might name these values what they are costs for, so we can use the vector of strategy names [v_names_str] to name the values:

names (v_tc_d) <- v_names_str
v_tc_d

names (v_tu_d) <- v_names_str
v_tu_d


# For utility, the utility values aren't different for the different states depending on the treatment strategy, i.e. SOC, Treatment A and Treatment B, but the time spent in the states with the associated utility is different due to the treatment you're on, so your utility value will be higher if the treatment keeps you well for longer so that you stay in a higher utility state for longer than a lower utility state, i.e., progression.


# Dataframe with discounted costs and effectiveness

# So then we aggregate them into a dataframe with our discounted costs and utilities, and then we use this to calculate ICERs in: ## 07.3 Compute ICERs of the Markov model

df_ce <- data.frame(Strategy = v_names_str,
                    Cost     = v_tc_d, 
                    Effect   = v_tu_d)
df_ce
```

## 07.3 Compute ICERs of the Markov model

(If I wanted to take a Net Monetary Benefit (NMB) approach instead, I could go to the 35 minute mark of: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop \_ DARTH\August\_24\Live Session Recording\Live Session Recording August 24th.mp4)

```{r}
df_cea <- calculate_icers(cost       = df_ce$Cost,
                          effect     = df_ce$Effect,
                          strategies = df_ce$Strategy
                          )
df_cea

# The above uses the DARTHtools package to calculate our ICERS, incremental cost and incremental effectiveness, and also describes dominance status:

# This uses the "calculate_icers function", which does all the sorting, all the prioritization, and then computes the dominance, and not dominance, etc., and there's a publication on the methods behind this, based on a method from colleagues in Stanford.

# The default view is ordered by dominance status (ND = non-dominated, ED = extended/weak dominance, or D= strong dominance), and then ascending by cost per: https://cran.r-project.org/web/packages/dampack/vignettes/basic_cea.html


# The icer object can be easily formatted into a publication quality table using the kableExtra package.

# library(kableExtra)
# library(dplyr)
# df_cea %>%
#  kable() %>%
#  kable_styling()


```

## 07.4 Plot frontier of the Markov model

```{r}
plot(df_cea, effect_units = "QALYs", label = "all")

# When we plot it we have 3 strategies it is possible that something would be off the frontier, would be weakly dominated or strongly dominated, with just a few strategies it's not necessarily that impressive, but with lots of strategies then dampack can be helpful.

```

The bottom axis of the above diagram shows you how effective the intervention is, the y axis shows you how costly the intervention is, here standard of care is cheaper but less effective than treatment B, which is more effective but more expensive, treatment A is not on the frontier, it has been dominated.

(If I wanted to see an example where the frontier doesnt exist, I could go to the 38 minute mark of: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop \_ DARTH\August\_24\Live Session Recording\Live Session Recording August 24th.mp4)

<https://www.google.ie/search?q=icer+fronter&hl=en&dcr=0&ei=nerzYYS_AciHhbIPlqyMuAk&ved=0ahUKEwjEgar1wdT1AhXIQ0EAHRYWA5cQ4dUDCA4&uact=5&oq=icer+fronter&gs_lcp=Cgdnd3Mtd2l6EAMyBwghEAoQoAE6BwgAEEcQsAM6BQgAEJECOgsIABCABBCxAxCDAToOCC4QgAQQsQMQxwEQowI6CwguELEDEMcBEK8BOg4ILhCABBCxAxDHARDRAzoICAAQsQMQgwE6BQguEJECOgQIABBDOgcIABCxAxBDOggIABCABBCxAzoOCC4QgAQQsQMQxwEQrwE6CAguEIAEELEDOgcIABDJAxBDOgUIABCSAzoFCAAQgAQ6CwguEIAEEMcBENEDOgUILhCABDoLCC4QgAQQxwEQrwE6BAgAEAo6CgguEMcBENEDEAo6BAguEAo6BwgAEMkDEAo6BggAEBYQHjoICAAQFhAKEB46BAgAEA06BQghEKABSgQIQRgASgQIRhgAUKIJWJYZYNEbaANwAngAgAGMAYgB6AiSAQM4LjSYAQCgAQHIAQjAAQE&sclient=gws-wiz>

<https://yhec.co.uk/glossary/cost-effectiveness-frontier/>

[\<https://www.hiqa.ie/sites/default/files/2017-01/Revised_Economic_Guidelines_posted_100714.pdf\>](https://www.hiqa.ie/sites/default/files/2017-01/Revised_Economic_Guidelines_posted_100714.pdf){.uri} [also saved here: C:\\Users\\Jonathan\\OneDrive - Royal College of Surgeons in Ireland\\COLOSSUS\\R Code\\GitHub\\COLOSSUS_Model\\Revised_Economic_Guidelines_posted_100714.pdf]

<https://researchonline.lshtm.ac.uk/id/eprint/4648686/1/The%20efficiency-frontier%20approach%20for%20health_GREEN%20AAM.pdf> also saved here:C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\R Code\GitHub\COLOSSUS\_Model\The efficiency-frontier approach for health_GREEN AAM.pdf

The efficiency frontier is described on page 277 [in the textbook] of: [file:///C:/Users/Jonathan/OneDrive%20-%20Royal%20College%20of%20Surgeons%20in%20Ireland/COLOSSUS/R%20Code/GitHub/COLOSSUS_Model/(Cambridge%20medicine)%20Hunink,%20M.%20G.%20Myriam_Weinstein,%20Milton%20C%20-%20Decision%20making%20in%20health%20and%20medicine\_%20integrating%20evidence%20and%20values.pdf](file:///C:/Users/Jonathan/OneDrive%20-%20Royal%20College%20of%20Surgeons%20in%20Ireland/COLOSSUS/R%20Code/GitHub/COLOSSUS_Model/(Cambridge%20medicine)%20Hunink,%20M.%20G.%20Myriam_Weinstein,%20Milton%20C%20-%20Decision%20making%20in%20health%20and%20medicine_%20integrating%20evidence%20and%20values.pdf)

# **Sensitivity Analysis Below:**

I've put detailed notes in:

C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop \_ DARTH\August\_27\\3_SA_material\markov\_sick-sicker_SA_solutions

Which should be read in tangent with: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Decision Modelling - Advanced Course\A2_Making Models Probabilistic\A2.1.2 Distributions for parameters\notes.txt

when doing the sensitivity analysis below:

# 08 Deterministic Sensitivity Analysis

## 08.1 List of input parameters

Create list `l_params_all` with all input probabilities, cost and utilities.

```{r}
l_params_all <- as.list(data.frame(
  p_HD      = 0.01,  # probability of dying when OS
  p_HS_SoC  = 0.05,  # probability of becoming PFS when OS, under standard of care
  p_HS_trtA = 0.04,  # probability of becoming PFS when OS, under treatment A
  p_HS_trtB = 0.02,  # probability of becoming PFS when OS, under treatment B
  p_SD      = 0.1,   # probability of dying when PFS
  c_H       = 400,   # cost of one cycle in OS state
  c_S       = 1000,  # cost of one cycle in PFS state
  c_D       = 0,     # cost of one cycle in dead state
  c_trtA    = 800,   # cost of treatment A (per cycle)
  c_trtB    = 1500,  # cost of treatment B (per cycle)
  u_H       = 1,     # utility when OS 
  u_S       = 0.5,   # utility when PFS
  u_D       = 0,     # utility when dead
  d_e       = 0.03,  # discount factor for effectiveness
  d_c       = 0.03   # discount factor for costs
))

# store the parameter names into a vector
v_names_params <- names(l_params_all)
```

## 08.2 Load PFS-PFSer Markov model function

To make the function work for my health states I rename "health" and "sick" in it to "PFS" and "OS" respectively.

```{r}
source("Functions_markov_3state.R")
# Test function
calculate_ce_out(l_params_all)
```

## 08.3 One-way sensitivity analysis (OWSA)

```{r}
options(scipen = 999) # disabling scientific notation in R
# dataframe containing all parameters, their base case values, and the min and 
# max values of the parameters of interest 
df_params_owsa <- data.frame(pars = c("c_trtA", "c_trtB", "c_S"),
                             min  = c(300 , 500, 500),  # min parameter values
                             max  = c(1200, 2000, 2000)  # max parameter values
)

owsa_nmb  <- run_owsa_det(params_range     = df_params_owsa,    # dataframe with parameters for OWSA
                          params_basecase  = l_params_all,      # list with all parameters
                          nsamp            = 100,               # number of parameter values
                          FUN              = calculate_ce_out,  # function to compute outputs
                          outcomes         = c("NMB"),          # output to do the OWSA on
                          strategies       = v_names_str,       # names of the strategies
                          n_wtp            = 5000)              # extra argument to pass to FUN
```

## 08.3.1 Plot OWSA

```{r}
plot(owsa_nmb, txtsize = 10, n_x_ticks = 4, 
     facet_scales = "free") +
  theme(legend.position = "bottom")
```

## 08.3.2 Optimal strategy with OWSA

```{r}
owsa_opt_strat(owsa = owsa_nmb, txtsize = 10)
```

## 08.3.3 Tornado plot

```{r}
owsa_tornado(owsa = owsa_nmb, txtsize = 11)
```

## 08.4 Two-way sensitivity analysis (TWSA)

```{r}
# dataframe containing all parameters, their basecase values, and the min and 
# max values of the parameters of interest
df_params_twsa <- data.frame(pars = c("c_trtA", "c_trtB"),
                             min  = c(300, 500),  # min parameter values
                             max  = c(1200, 2000) # max parameter values
)

twsa_nmb <- run_twsa_det(params_range    = df_params_twsa,    # dataframe with parameters for TWSA
                         params_basecase = l_params_all,      # list with all parameters
                         nsamp           = 40,                # number of parameter values
                         FUN             = calculate_ce_out,  # function to compute outputs
                         outcomes        = "NMB",             # output to do the TWSA on
                         strategies      = v_names_str,       # names of the strategies
                         n_wtp           = 5000)              # extra argument to pass to FUN
```

## 08.4.1 Plot TWSA

```{r}
plot(twsa_nmb)
```

# 09 Probabilistic Sensitivity Analysis (PSA)

```{r}
# Function to generate PSA input dataset
gen_psa <- function(n_sim = 1000, seed = 071818){
  set.seed(seed) # set a seed to be able to reproduce the same results
  df_psa <- data.frame(
    # Transition probabilities (per cycle), conditional on surviving
    # probability to become PFS when OS
    # probability of dying when OS
    p_HD       = rbeta(n_sim, shape1 = 4,  shape2 = 391),
    p_HS_SoC   = rbeta(n_sim, shape1 = 24, shape2 = 450),  # under standard of care
    p_HS_trtA  = rbeta(n_sim, shape1 = 15, shape2 = 368),  # under treatment A
    p_HS_trtB  = rbeta(n_sim, shape1 = 16, shape2 = 767),  # under treatment B
    
    # probability of dying when PFS
    p_SD       = rbeta(n_sim, shape1 = 22.4, shape2 = 201.6), 
    
    # Cost vectors with length n_sim
    # cost of remaining one cycle in state H
    c_H        = rgamma(n_sim, shape = 16, scale = 25), 
    # cost of remaining one cycle in state S1
    c_S        = rgamma(n_sim, shape = 100, scale = 10), 
    # cost of being in the death state
    c_D        = 0, 
    # cost of treatment (per cycle)
    c_trtA    = rgamma(n_sim, shape = 64, scale = 12.5),
    # cost of treatment (per cycle)
    c_trtB    = rgamma(n_sim, shape = 225, scale = 6.67),
    
    # Utility vectors with length n_sim 
    # utility when OS
    u_H        = rbeta(n_sim, shape1 =  1.5, shape2 = 0.0015), 
    # utility when PFS
    u_S        = rbeta(n_sim, shape1 = 49.5, shape2 = 49.5), 
    # utility when dead
    u_D        = 0                                              
  )
  return(df_psa)
}


# Try it
gen_psa(10) 

# Number of simulations
n_sim <- 1000

# Generate PSA input dataset
df_psa_input <- gen_psa(n_sim = n_sim)
# First six observations
head(df_psa_input)

# Save the dataframe
# save dataframe
#save(df_psa_input, file = "df_psa_input.rda")


# Histogram of parameters
ggplot(melt(df_psa_input, variable.name = "Parameter"), aes(x = value)) +
  facet_wrap(~Parameter, scales = "free") +
  geom_histogram(aes(y = ..density..)) +
  theme_bw(base_size = 16) + 
  theme(axis.text = element_text(size=8))

# Initialize dataframes with PSA output 
# Dataframe of costs
df_c <- as.data.frame(matrix(0, 
                             nrow = n_sim,
                             ncol = n_str))
colnames(df_c) <- v_names_str
# Dataframe of effectiveness
df_e <- as.data.frame(matrix(0, 
                             nrow = n_sim,
                             ncol = n_str))
colnames(df_e) <- v_names_str
```

I need to fix the "\# Histogram of parameters" section above, the below gives advice on doing this:

<https://stackoverflow.com/questions/68416435/rcpp-package-doesnt-include-rcpp-precious-remove>

[https://www.mail-archive.com/rcpp-devel\@lists.r-forge.r-project.org/msg10226.html](https://www.mail-archive.com/rcpp-devel@lists.r-forge.r-project.org/msg10226.html){.uri}

<https://statisticsglobe.com/warning-cannot-remove-prior-installation-in-r>

The above approach worked, I manually deleted the package, installed darthtools from github, chose option 4, i.e. replace rccp and then I was done.

## 09.1 Conduct probabilistic sensitivity analysis

```{r}
# Run Markov model on each parameter set of PSA input dataset
for(i in 1:n_sim){
  l_out_temp <- calculate_ce_out(df_psa_input[i, ])
  df_c[i, ] <- l_out_temp$Cost
  df_e[i, ] <- l_out_temp$Effect
  # Display simulation progress
  if(i/(n_sim/10) == round(i/(n_sim/10), 0)) { # display progress every 10%
    cat('\r', paste(i/n_sim * 100, "% done", sep = " "))
  }
}
```

## 09.2 Create PSA object for dampack

```{r}
l_psa <- make_psa_obj(cost          = df_c, 
                      effectiveness = df_e, 
                      parameters    = df_psa_input, 
                      strategies    = v_names_str)
```

## 09.2.1 Save PSA objects

```{r}
save(df_psa_input, df_c, df_e, v_names_str, n_str, l_psa,
     file = "markov_3state_PSA_dataset.RData")
```

Vector with willingness-to-pay (WTP) thresholds.

```{r}
v_wtp <- seq(0, 30000, by = 1000)
```

## 09.3.1 Cost-Effectiveness Scatter plot

```{r}
plot(l_psa, xlim = c(9.5, 22.5))
```

## 09.4 Conduct CEA with probabilistic output

```{r}
# Compute expected costs and effects for each strategy from the PSA
df_out_ce_psa <- summary(l_psa)

# Calculate incremental cost-effectiveness ratios (ICERs)
df_cea_psa <- calculate_icers(cost       = df_out_ce_psa$meanCost, 
                              effect     = df_out_ce_psa$meanEffect,
                              strategies = df_out_ce_psa$Strategy)
df_cea_psa

# Save CEA table with ICERs
# As .RData
save(df_cea_psa, 
     file = "markov_3state_probabilistic_CEA_results.RData")
# As .csv
write.csv(df_cea_psa, 
          file = "markov_3state_probabilistic_CEA_results.csv")
```

## 09.4.1 Plot cost-effectiveness frontier

```{r}
plot(df_cea_psa)
```

## 09.4.2 Cost-effectiveness acceptability curves (CEACs) and frontier (CEAF)

```{r}
ceac_obj <- ceac(wtp = v_wtp, psa = l_psa)
# Regions of highest probability of cost-effectiveness for each strategy
summary(ceac_obj)
# CEAC & CEAF plot
plot(ceac_obj)
```

## 09.4.3 Expected Loss Curves (ELCs)

The expected loss is the the quantification of the foregone benefits when choosing a suboptimal strategy given current evidence.

```{r}
elc_obj <- calc_exp_loss(wtp = v_wtp, psa = l_psa)
elc_obj
# ELC plot
plot(elc_obj, log_y = FALSE)
```

## 09.4.4 Expected value of perfect information (EVPI)

```{r}
evpi <- calc_evpi(wtp = v_wtp, psa = l_psa)
# EVPI plot
plot(evpi, effect_units = "QALY")
```

## References:

Useful Darth publications to cite when using this code:

-   Jalal H, Pechlivanoglou P, Krijkamp E, Alarid-Escudero F, Enns E, Hunink MG. An Overview of R in Health Decision Sciences.
    Med Decis Making.
    2017; 37(3): 735-746.
    <https://journals.sagepub.com/doi/abs/10.1177/0272989X16686559>

-   Alarid-Escudero F, Krijkamp EM, Enns EA, Yang A, Hunink MGM Pechlivanoglou P, Jalal H. Cohort State-Transition Models in R: A Tutorial.
    arXiv:200107824v2.
    2020:1-48.
    <http://arxiv.org/abs/2001.07824>

-   Krijkamp EM, Alarid-Escudero F, Enns EA, Jalal HJ, Hunink MGM, Pechlivanoglou P. Microsimulation modeling for health decision sciences using R: A tutorial.
    Med Decis Making.
    2018;38(3):400--22.
    <https://journals.sagepub.com/doi/abs/10.1177/0272989X18754513>

-   Krijkamp EM, Alarid-Escudero F, Enns E, Pechlivanoglou P, Hunink MM, Jalal H. A Multidimensional Array Representation of State-Transition Model Dynamics.
    Med Decis Making.
    Online First <https://doi.org/10.1177/0272989X19893973>
