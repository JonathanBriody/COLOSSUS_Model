# When I do have data, the data needs to be set up to include a column for the time (in the example this is time in years) and a status indicator whether the time corresponds to an event, i.e. progression (status = 1), or to the last time of follow up, i.e. censoring (status = 0),
# "What is Censoring? Censoring in a study is when there is incomplete information about a study participant, observation or value of a measurement. In clinical trials, it's when the event doesn't happen while the subject is being monitored or because they drop out of the trial." - https://www.statisticshowto.com/censoring/#:~:text=What%20is%20Censoring%3F,drop%20out%20of%20the%20trial.
# https://en.wikipedia.org/wiki/Survival_analysis#:~:text=or%20q%20%3D%200.99.-,Censoring,is%20common%20in%20survival%20analysis.
# At the bottom of the parametric survival code I think about how time from individual patient data may be changed to match the time of our cycles.
# I think the digitiser will give me the time in the context of the survival curves I am digitising, i.e., time in weeks, or time in months or time in years.
# Then I will have to set-up my time accordingly in the R code so that my cycle length is at the same level as the individual patient data.
# That is, in Koen's example:
# C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\R Code\Parametric Survival Analysis\ISPOR WEBINAR Health Economic Modelling in R\ISPOR_webinar_R-master
# the data includes a column for the time (in years)
# t_cycle <- 1/4      # cycle length of 3 months (in years)                                # n_cycle <- 60       # number of cycles (total runtime 15 years)
# So I would have my colum for time, in the [TIME] the graph I was digitising used.
# Then I would create my cycle length of X weeks (in [TIME] the graph I was digitising used)
# Then I would have my number of cycles that would add up to give me a total runtime of how long I want to run the model for.
# So, above Koen wanted to run the model for 15 years, but his cycles were in 3 months, or each cycle was a quarter of a year, so 60 quarters, or 60 3 month cycles, is 15 years.
# We will implement a semi-Markov model with time-dependent transition probabilities, via a parametric survival model fitted to some individual patient data for the time-to-progression (TTP) and time-to-death (TTD) for standard of care.
# A hazard ratio for the new intervention therapy vs. the standard of care will then be applied to obtain transition probabilities for the new experimental strategy.
# We use the 'flexsurv' package to fit several commonly used parametric survival distributions.
# The data needs to be set up to include a column for the time (in years) and a status indicator whether the time corresponds to an event, i.e. progression (status = 1), or to the last time of follow up, i.e. censoring (status = 0).
# It looks like Koen is applying the flexsurvreg formula to individuals who experience progression (i.e. ~1):
head(df_TTP)
l_TTP_SoC_exp      <- flexsurvreg(formula = Surv(time, status) ~ 1, data = df_TTP, dist = "exp")
l_TTP_SoC_gamma    <- flexsurvreg(formula = Surv(time, status) ~ 1, data = df_TTP, dist = "gamma")
l_TTP_SoC_gompertz <- flexsurvreg(formula = Surv(time, status) ~ 1, data = df_TTP, dist = "gompertz")
l_TTP_SoC_llogis   <- flexsurvreg(formula = Surv(time, status) ~ 1, data = df_TTP, dist = "llogis")
l_TTP_SoC_lnorm    <- flexsurvreg(formula = Surv(time, status) ~ 1, data = df_TTP, dist = "lnorm")
l_TTP_SoC_weibull  <- flexsurvreg(formula = Surv(time, status) ~ 1, data = df_TTP, dist = "weibull")
# And this would make sense per the below diagram - which looks at the proportion of individuals who have the event, i.e. progression.
# Inspect fit based on visual fit
colors <- rainbow(6)
plot(l_TTP_SoC_exp,       col = colors[1], ci = FALSE, ylab = "Event-free proportion", xlab = "Time in years", las = 1)
lines(l_TTP_SoC_gamma,    col = colors[2], ci = FALSE)
lines(l_TTP_SoC_gompertz, col = colors[3], ci = FALSE)
lines(l_TTP_SoC_llogis,   col = colors[4], ci = FALSE)
lines(l_TTP_SoC_lnorm,    col = colors[5], ci = FALSE)
lines(l_TTP_SoC_weibull,  col = colors[6], ci = FALSE)
legend("right",
legend = c("exp", "gamma", "gompertz", "llogis", "lnorm", "weibull"),
col    = colors,
lty    = 1,
bty    = "n")
# Koen says "# Weibull has the best visual and numerical fit" but I don't see what it's visually being compared to in this graph, I will have to learn about this in the C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\R Code\Parametric Survival Analysis\flexsurv folder.
# The time is in years which makes sense, the data you are drawing from is in years so that's what you want to make comparisons to.
# Compare the fit numerically based on the AIC
(v_AIC <- c(
exp      = l_TTP_SoC_exp$AIC,
gamma    = l_TTP_SoC_gamma$AIC,
gompertz = l_TTP_SoC_gompertz$AIC,
llogis   = l_TTP_SoC_llogis$AIC,
lnorm    = l_TTP_SoC_lnorm$AIC,
weibull  = l_TTP_SoC_weibull$AIC
))
# Weibull has the best visual and numerical fit
# I will have to learn what a good value of AIC is, and, because flexsurvreg provides AIC I will have to see what other numerical measures, such as BIC, it provides.
# Saving the survival parameters ----
# The 'flexsurv' package return the coefficients, which need to be transformed for use in the base R functions, but that will be done when the coefficients actually are used, for the time being we will just save the survival parameters from the distribution we decide to use.
# NB, if we are not going with Weibull then we may have to save something specific to the distribution that is not shape or scale - we can look into this if we don't use Weibull.
l_TTP_SoC_weibull
# Calling a flexsurvreg parameter like this allows you to see here that Weibull is the shape and the scale, so if we do go with another distribution we can see what it's version of shape and scale are and use these instead.
l_TTP_SoC_weibull$coefficients
coef_weibull_shape_SoC <- l_TTP_SoC_weibull$coefficients["shape"]
coef_weibull_scale_SoC <- l_TTP_SoC_weibull$coefficients["scale"]
# We use the 'flexsurv' package to fit several commonly used parametric survival distributions.
# The data needs to be set up to include a column for the time (in years) and a status indicator whether the time corresponds to an event, i.e. progression (status = 1), or to the last time of follow up, i.e. censoring (status = 0).
# It looks like Koen is applying the flexsurvreg formula to individuals who experience progression (i.e. ~1):
# I duplicate the time to progression data frame as time to dead here, I'll REALLY need to make sure to delete this line when I have actual time to dead data or else I'll be running my analysis on the time to progression data twice and thinking I'm running it on time to dead:
df_TTD <- df_TTP
head(df_TTD)
l_TTD_SoC_exp      <- flexsurvreg(formula = Surv(time, status) ~ 1, data = df_TTD, dist = "exp")
l_TTD_SoC_gamma    <- flexsurvreg(formula = Surv(time, status) ~ 1, data = df_TTD, dist = "gamma")
l_TTD_SoC_gompertz <- flexsurvreg(formula = Surv(time, status) ~ 1, data = df_TTD, dist = "gompertz")
l_TTD_SoC_llogis   <- flexsurvreg(formula = Surv(time, status) ~ 1, data = df_TTD, dist = "llogis")
l_TTD_SoC_lnorm    <- flexsurvreg(formula = Surv(time, status) ~ 1, data = df_TTD, dist = "lnorm")
l_TTD_SoC_weibull  <- flexsurvreg(formula = Surv(time, status) ~ 1, data = df_TTD, dist = "weibull")
# And this would make sense per the below diagram - which looks at the proportion of individuals who have the event, i.e. progression.
# Inspect fit based on visual fit
colors <- rainbow(6)
plot(l_TTD_SoC_exp,       col = colors[1], ci = FALSE, ylab = "Event-free proportion", xlab = "Time in years", las = 1)
lines(l_TTD_SoC_gamma,    col = colors[2], ci = FALSE)
lines(l_TTD_SoC_gompertz, col = colors[3], ci = FALSE)
lines(l_TTD_SoC_llogis,   col = colors[4], ci = FALSE)
lines(l_TTD_SoC_lnorm,    col = colors[5], ci = FALSE)
lines(l_TTD_SoC_weibull,  col = colors[6], ci = FALSE)
legend("right",
legend = c("exp", "gamma", "gompertz", "llogis", "lnorm", "weibull"),
col    = colors,
lty    = 1,
bty    = "n")
# Koen says "# Weibull has the best visual and numerical fit" but I don't see what it's visually being compared to in this graph, I will have to learn about this in the C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\R Code\Parametric Survival Analysis\flexsurv folder.
# The time is in years which makes sense, the data you are drawing from is in years so that's what you want to make comparisons to.
# Saving the survival parameters ----
# The 'flexsurv' package return the coefficients, which need to be transformed for use in the base R functions, but that will be done when the coefficients actually are used, for the time being we will just save the survival parameters from the distribution we decide to use.
# NB, if we are not going with Weibull then we may have to save something specific to the distribution that is not shape or scale - we can look into this if we don't use Weibull.
l_TTD_SoC_weibull
# Calling a flexsurvreg parameter like this allows you to see here that Weibull is the shape and the scale, so if we do go with another distribution we can see what it's version of shape and scale are and use these instead.
l_TTD_SoC_weibull$coefficients
coef_TTD_weibull_shape_SoC <- l_TTD_SoC_weibull$coefficients["shape"]
coef_TTD_weibull_scale_SoC <- l_TTD_SoC_weibull$coefficients["scale"]
# all functions are in the darthtools package
# There is a functions RMD for the PSA stuff below, instead of calling it in: ## 08.2 Load PFS-PFSer Markov model function, I could just place it here, and place all the necessary packages above and then I would only ever need 1 R Markdown document for the entire study. Will think about doing this.
## General setup
# Why ordering, V_names_states v_tc_SoC, v_tc_Exp,  v_tu_SoC and v_tu_Exp matters:
# The ordering of V_names_states has an influence on the tornado diagram and the reported cost-effectiveness results.
# So, I need to ensure I correctly order V_names_states all the way through from the start.
# m_P_Exp and m_P_SoC both use v_names_states to set up the names of the rows and columns of their matrices.
# As does m_M_SoC and m_M_Exp.
# Then m_M_SoC and  m_M_Exp use the row column names to fill in the 100% of the cohort (or 1) in PFS and the 0% of the cohort in AE1, AE2, AE3, OS and DEAD in wave 1. m_P_Exp and m_P_SoC also both use the row and column names to fill in the transition probabilities between PFS and OS, etc.,
# Then m_M_SoC and m_M_Exp are matrix multiplied by m_P_Exp and m_P_SoC:
# for(i_cycle in 1:(n_cycle-1)) {
#  m_M_SoC[i_cycle + 1, ] <- m_M_SoC[i_cycle, ] %*% m_P_SoC[ , , i_cycle]
#  m_M_Exp[i_cycle + 1, ] <- m_M_Exp[i_cycle, ] %*% m_P_Exp[ , , i_cycle]
# }
# The way this matrix multiplication works is that the value in box 1 for m_M_SoC is multiplied by the value in box 1 for m_P_SoC and so on. If box 1 for m_M_SoC and m_P_SoC is the 1 (i.e. 100% of people in the PFS state when this all starts), multiplied by the PFS state probabilities, i.e., the probability of going from the PFS state into other states like so:
#          PFS       AE1       AE2       AE3          OS        Dead
# PFS  0.974925 0.0194985 0.0194985 0.0194985 0.005074995 0.020000000
# Then things will multiply correctly and we're multiplying PFS transition probabilities by the 100% of the cohort in the PFS state.
# Even, if ordering v_names_states  <- c("PFS", "AE1", "AE2", "AE3", "OS", "Dead")   is not in the order as above, i.e., v_names_states  <- c("OS", "AE1", "AE2", "AE3", "PFS", "Dead") , then the m_M_SoC will have 0, 0, 0, 0, 1, 0, because everyone still starts in the PFS state, and m_P_SoC will have  "OS", "AE1", "AE2", "AE3", "PFS", "Dead", with the right probabilities put in the right spots, so when you matrix multiply it things will multiply out fine.
# However, this is not the case for ordering costs and utilities:
# v_tc_SoC <- m_M_SoC %*% c(c_F_SoC, c_AE1, c_AE2, c_AE3, c_P, c_D)
# v_tc_Exp <- m_M_Exp %*% c(c_F_Exp, c_AE1, c_AE2, c_AE3, c_P, c_D)
# v_tu_SoC <- m_M_SoC %*% c(u_F, u_AE1, u_AE2, u_AE3, u_P, u_D)
# v_tu_Exp <- m_M_Exp %*% c(u_F, u_AE1, u_AE2, u_AE3, u_P, u_D)
# As you can see, in both cases the ordering is set manually by how we enter things in the concatenated brackets, so in the case above where ordering v_names_states  <- c("PFS", "AE1", "AE2", "AE3", "OS", "Dead") is ordered differently, i.e., v_names_states  <- c("OS", "AE1", "AE2", "AE3", "PFS", "Dead") when we matrix multiply costs and utilities by m_M_SoC  and m_M_Exp above we will be multiplying the utility of being in the progression free state u_F by the matrix of individuals in the OS state, which will clearly be a smaller number of individuals in the first few waves, and multiplying the utility of the OS state (u_P) by the larger number of individuals actually in the PFS state <- c("OS", "AE1", "AE2", "AE3", "PFS", "Dead"). We'll be doing the same thing with costs. What this will mean is more people getting the OS costs and OS utility and fewer people getting the PFS costs and the PFS utility, which will in turn have consequences for the cost-effectiveness analysis results with more OS costs and more OS utility being considered in the equation that compares costs and utilities.
# I've confirmed all of the things I say about by changing the ordering first of v_names_states, and then of the cost and utility concatenations. Changing the ordering of v_names_states did nothing to the CEA results or Tornado diagram provided I changed the ordering of utilities and costs to match this, changing the ordering of utilities and costs changed both unless I changed them to be in an order that matched the changed ordering of v_names_states.
# Here we define all our model parameters, so that we can call on these parameters later during our model:
t_cycle <- 1/2      # cycle length of 2 weeks (in [[months]] - this is assuming the survival curves I am digitising will be in [[months]] if they are in another period I will have to represent my cycle length in that period instead).
n_cycle        <- 120
# We set the number of cycles to 120 to reflect 5 years broken down into fortnightly cycles
v_names_cycles  <- paste("cycle", 0:n_cycle)
# So here, we just name each cycle by the cycle its on, going from 0 up to the number of cycles there are, here 120.
v_names_states  <- c("PFS", "AE1", "AE2", "AE3", "OS", "Dead")
# These are the health states in our model, PFS, Adverse Event 1, Adverse Event 2, Adverse Event 3, OS, Death.
n_states        <- length(v_names_states)
# We're just taking the number of health states from the number of names we came up with, i.e. the number of names to reflect the number of health states
# Strategy names
v_names_strats     <- c("Standard of Care",
#"EPI Assay", ## AKA Treatment A
#"HDX Assay") ## AKA Treatment B
"Experimental Treatment") ## AKA Treatment B
# store the strategy names
n_str           <- length(v_names_strats)
# number of strategies
# TRANSITION PROBABILITIES: Time-To-Transition - TTP:
# Time-dependent transition probabilities are obtained in four steps
# 1) Defining the cycle times
# 2) Obtaining the event-free (i.e. survival) probabilities for the cycle times for SoC
# 3) Obtaining the event-free (i.e. survival) probabilities for the cycle times for Exp based on a hazard ratio
# 4) Obtaining the time-dependent transition probabilities from the event-free (i.e. survival) probabilities
# 1) Defining the cycle times
(t <- seq(from = 0, by = t_cycle, length.out = n_cycle + 1))
# I think here we're saying, at each cycle how many of the time periods our individual patient data is measured at have passed? Here our individual patient data is in months, so we have 0 in cycle 0, 0.5 or half a month in cycle 1, and so on.
# Having established that allows us to obtain the transition probabilities for the time we are interested in for our cycles from this longer period individual patient data, so where the individual patient data is in months and our cycles are in fortnight or half months, this allows us to obtain transition probabilities for these fortnights.
# 2) Obtaining the event-free (i.e. survival) probabilities for the cycle times for SoC
# S_FP_SoC - survival of progression free to progression, i.e. not going to progression, i.e. staying in progression free.
# Note that the coefficients [that we took from flexsurvreg earlier] need to be transformed to obtain the parameters that the base R function uses
S_FP_SoC <- pweibull(
q     = t,
shape = exp(coef_weibull_shape_SoC),
scale = exp(coef_weibull_scale_SoC),
lower.tail = FALSE
)
head(cbind(t, S_FP_SoC))
#        t  S_FP_SoC
# [1,] 0.0 1.0000000
# [2,] 0.5 0.9948214
# [3,] 1.0 0.9770661
# [4,] 1.5 0.9458256
# [5,] 2.0 0.9015175
# [6,] 2.5 0.8454597
# Having the above header shows that this is probability for surviving in the F->P state, i.e., staying in this state, because you can see in time 0 100% of people are in this state, meaning 100% of people hadnt progressed and were in PFS, if this was instead about the progressed state (i.e. OS), there should be no-one in this state when the model starts, as everyone starts in the PFS state, and it takes a while for people to reach the OS state.
# 3) Obtaining the event-free (i.e. survival) probabilities for the cycle times for Experimental treatment (aka the novel therapy) based on a hazard ratio.
# So here we basically have a hazard ratio for the novel therapy that says you do X much better under the novel therapy than under standard of care, and we want to apply it to standard of care from our individual patient data to see how much improved things would be under the novel therapy.
# (NB - if we ultimately decide not to use a hazard ratio, I could probably just create my transition probabilities for the experimental therapy from individual patient data that I have digitised from patients under this novel therapy).
# Here our hazard ratio is 0.6, I can change that for our hazard ratio.
# - note that S(t) = exp(-H(t)) and, hence, H(t) = -ln(S(t))
# that is, the survival function is the expoential of the negative hazard function, per:
# https://faculty.washington.edu/yenchic/18W_425/Lec5_survival.pdf
# and:
# https://web.stanford.edu/~lutian/coursepdf/unit1.pdf
# Also saved here: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\R Code\Parametric Survival Analysis\flexsurv
# And to multiply by the hazard ratio it's necessary to convert the survivor function into the hazard function, multiply by the hazard ratio, and then convert back to the survivor function, and then these survivor functions are used for the probabilities.
HR_FP_Exp <- 0.6
H_FP_SoC  <- -log(S_FP_SoC)
H_FP_Exp  <- H_FP_SoC * HR_FP_Exp
S_FP_Exp  <- exp(-H_FP_Exp)
head(cbind(t, S_FP_SoC, H_FP_SoC, H_FP_Exp, S_FP_Exp))
head(cbind(t, S_FP_SoC, H_FP_SoC))
# I want to vary my probabilities for the one-way sensitivity analysis, particularly for the tornado       plot of the deterministic sensitivity analysis.
# The problem here is that df_params_OWSA doesnt like the fact that a different probability for each       cycle (from the time-dependent transition probabilities) gives 122 rows (because there are 60 cycles,      two treatment strategies and a probability for each cycle). It wants the same number of       rows as      there are probabilities, i.e., it would prefer a probability of say 0.50 and then a max and a      min     around that.
# To address this, I think I can apply this mean, max and min to the hazard ratios instead, knowing        that when run_owsa_det is run in the sensitivity analysis it calls this function to run and in this        function the hazard ratios generate the survivor function, and then these survivor functions are used      to generate the probabilities (which will be cycle dependent).
# This is fine for the hazard ratio for the experimental strategy, I can just take:
# HR_FP_Exp as my mean, and:
# Minimum_HR_FP_Exp <- HR_FP_Exp - 0.20*HR_FP_Exp
# Maximum_HR_FP_Exp <- HR_FP_Exp + 0.20*HR_FP_Exp
# For min and max.
# For standard of care there was no hazard ratio, because we took these values from the survival curves     directly, and didnt vary them by a hazard ratio, like we do above.
# To address this, I create a hazard ratio that is exactly one.
# hazard ratio
# A measure of how often a particular event happens in one group compared to how often it happens in       another group, over time. In cancer research, hazard ratios are often used in clinical trials to           measure survival at any point in time in a group of patients who have been given a specific treatment      compared to a control group given another treatment or a placebo. A hazard ratio of one means that         there is no difference in survival between the two groups. A hazard ratio of greater than one or less      than one means that survival was better in one of the groups. https://www.cancer.gov/publications/dictionaries/cancer-terms/def/hazard-ratio
# Thus, I can have a hazard ratio where the baseline value of it gives you the survival curves, and        thus the probabilities, from the actual survival curves we are drawing from, and where the min and max     will be 1 +/- 0.20, which will give us probabilities that are 20% higher or lower than the probabilities from the actual survival curves that we are drawing from in the parametric survival analysis to get transitions under standard of care.
# To do this, I just have to add a hazard ratio to the code that creates the transition probabilities      under standard of care as below, then I can add that hazard ratio, and it's max and min, to the            deterministic sensitivity analysis and vary all the probabilities by 20%.
# So here we basically have a hazard ratio that is equal to 1, so it leaves things unchanged for           patients, and we want to apply it to standard of care from our individual patient data to leave things     unchanged in this function, but allow things to change in the sensitivity analysis.
# Here our hazard ratio is 1, things are unchanged.
# So, first we create our hazard ratio == 1
HR_FP_SoC <- 1
# (I'm creating the below as new parameters, i.e. putting "nu" infront of them, in case keeping the name the same causes a problem for when I want to use them in the deterministic sensivity analysis, i.e., if I generate a parameter from itself - say var_name = var_name exactly, then there may be some way in which R handles code that won't let this work, or will take one parameter before the other, or something and stop the model from executing correctly).
# Then, we create our hazard function for SoC:
NU_S_FP_SoC <- S_FP_SoC
NU_H_FP_SoC  <- -log(NU_S_FP_SoC)
# Then, we multiply this hazard function by our hazard ratio, which is just 1, but which gives us the      opportunity to apply a hazard ratio to standard of care in our code and thus to have a hazard ratio for     standard of care for our one way deterministic sensitivity analysis and tornado diagram.
NUnu_H_FP_SoC  <- NU_H_FP_SoC * HR_FP_SoC
# Again, I was worried that with overlap when creating parameters I would have a problem with the deterministic sensivity analysis so I call it NU again to make it a "new" parameter again.
NU_S_FP_SoC  <- exp(-NUnu_H_FP_SoC)
head(cbind(t, NU_S_FP_SoC, NUnu_H_FP_SoC))
# NU_H_FP_SoC  <- -log(NU_S_FP_SoC)
# # Then, we multiply this hazard function by our hazard ratio, which is just 1, but which gives us the      opportunity to apply a hazard ratio to standard of care in our code and thus to have a hazard ratio for     standard of care for our one way deterministic sensitivity analysis and tornado diagram.
# NU_H_FP_SoC  <- NU_H_FP_SoC * HR_FP_SoC
# #
# NU_S_FP_SoC  <- exp(-NU_H_FP_SoC)
#
# head(cbind(t, NU_S_FP_SoC, NU_H_FP_SoC))
# 4) Obtaining the time-dependent transition probabilities from the event-free (i.e. survival) probabilities
# Now we can take the probability of being in the PFS state at each of our cycles, as created above, from 100% (i.e. from 1) in order to get the probability of NOT being in the PFS state, i.e. in order to get the probability of moving into the progressed state, or the OS state.
p_FP_SoC <- p_FP_Exp <- rep(NA, n_cycle)
# First we make the probability of going from progression-free (F) to progression (P) blank (i.e. NA) for all the cycles in standard of care and all the cycles under the experimental strategy.
for(i in 1:n_cycle) {
p_FP_SoC[i] <- 1 - NU_S_FP_SoC[i+1] / NU_S_FP_SoC[i]
p_FP_Exp[i] <- 1 - S_FP_Exp[i+1] / S_FP_Exp[i]
}
# Then we generate our transition probability under standard of care and under the experimental treatement using survival functions that havent and have had the hazard ratio from above applied to them, respectively.
# The way this works is the below, you take next cycles probability of staying in this state, divide it by this cycles probability of staying in this state, and take it from 1 to get the probability of leaving this state.
# > head(cbind(t, S_FP_SoC))
#        t  S_FP_SoC
# [1,] 0.0 1.0000000
# [2,] 0.5 0.9948214
# [3,] 1.0 0.9770661
# [4,] 1.5 0.9458256
# [5,] 2.0 0.9015175
# [6,] 2.5 0.8454597
# > 1-0.9948214/1.0000000
# [1] 0.0051786
# > 0.9770661/0.9948214
# [1] 0.9821523
# > 1-0.9821523
# [1] 0.0178477
p_FP_SoC
#> p_FP_SoC
#  [1] 0.005178566 0.017847796 0.031973721 0.046845943 0.062181645
p_FP_Exp
# NOW I NEED TO REPEAT THE ABOVE, BUT THIS TIME FOR OS TO DEATH.
# AT THE MOMENT I'M JUST LEAVING THIS CHUNK OF CODE ALONE, AS I DON'T THINK I'LL BE USING IT...
# TRANSITION PROBABILITIES: Time-To-Dead TTD
# Time-dependent transition probabilities are obtained in four steps
# 1) Defining the cycle times [we already did this above]
# 2) Obtaining the event-free (i.e. overall survival) probabilities for the cycle times for SoC
# 3) Obtaining the event-free (i.e. overall survival) probabilities for the cycle times for Exp based on a hazard ratio if we think we will be applying a hazard ratio in the OS -> Death setting. Probably not, probably what we'll be doing is saying that once you get into the OS state under the experimental strategy, you recieve the same second-line treatment as standard of care again and thus your event-free (i.e. overall survival) probabilities for the cycle times are the same as for SoC. - I'll code in both options here and I can make a decision when applying this.
# 4) Obtaining the time-dependent transition probabilities from the event-free (i.e. overall survival) probabilities
# 1) Defining the cycle times
(t <- seq(from = 0, by = t_cycle, length.out = n_cycle + 1))
# 2) Obtaining the event-free (i.e. overall survival) probabilities for the cycle times for SoC
# S_PD_SoC - survival of progression to dead, i.e. not going to dead, i.e. staying in progression.
# Note that the coefficients [that we took from flexsurvreg earlier] need to be transformed to obtain the parameters that the base R function uses
S_PD_SoC <- pweibull(
q     = t,
shape = exp(coef_TTD_weibull_shape_SoC),
scale = exp(coef_TTD_weibull_scale_SoC),
lower.tail = FALSE
)
head(cbind(t, S_PD_SoC))
# Having the above header shows that this is probability for surviving in the P->D state, i.e., staying in this state, because you should see in time 0 0% of people are in this state, meaning 100% of people hadnt gone into the progressed state and were in PFS, which make sense in this model, the model starts with everyone in PFS, no-one starts the model in OS, and it takes a while for people to reach the OS state.
# 3) Obtaining the event-free (i.e. overall survival) probabilities for the cycle times for Experimental treatment (aka the novel therapy) based on a hazard ratio.
# So here we basically have a hazard ratio for the novel therapy that says you do X much better under the novel therapy than under standard of care, and we want to apply it to standard of care from our individual patient data to see how much improved things would be under the novel therapy.
# Here our hazard ratio is 0.6, I can change that for our hazard ratio.
# - note that S(t) = exp(-H(t)) and, hence, H(t) = -ln(S(t))
# that is, the survival function is the expoential of the negative hazard function, per:
# https://faculty.washington.edu/yenchic/18W_425/Lec5_survival.pdf
# and:
# https://web.stanford.edu/~lutian/coursepdf/unit1.pdf
# Also saved here: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\R Code\Parametric Survival Analysis\flexsurv
# And to multiply by the hazard ratio it's necessary to convert the survivor function into the hazard function, multiply by the hazard ratio, and then convery back to the survivor function, and then these survivor functions are used for the probabilities.
HR_PD_Exp <- 0.6
H_PD_SoC  <- -log(S_PD_SoC)
H_PD_Exp  <- H_PD_SoC * HR_PD_Exp
S_PD_Exp  <- exp(-H_PD_Exp)
head(cbind(t, S_PD_SoC, H_PD_SoC, H_PD_Exp, S_PD_Exp))
# If I decide that, as I said,  once you get into the OS state under the experimental strategy, you recieve the same second-line treatment as standard of care again and thus your event-free (i.e. overall survival) probabilities for the cycle times are the same as for SoC, then I can use the following coding - which is just repeating what I did for standard of care but this time giving it to the experimental stratgey:
S_PD_Exp <- pweibull(
q     = t,
shape = exp(coef_TTD_weibull_shape_SoC),
scale = exp(coef_TTD_weibull_scale_SoC),
lower.tail = FALSE
)
head(cbind(t, S_PD_Exp))
# I've coded in both options here and I can make a decision when applying this.
# 4) Obtaining the time-dependent transition probabilities from the event-free (i.e. overall survival) probabilities
# Now we can take the probability of being in the OS state at each of our cycles, as created above, from 100% (i.e. from 1) in order to get the probability of NOT being in the OS state, i.e. in order to get the probability of moving into the deda state.
p_PD_SoC <- p_PD_Exp <- rep(NA, n_cycle)
# First we make the probability of going from progression (P) to dead (D) blank (i.e. NA) for all the cycles in standard of care and all the cycles under the experimental strategy.
for(i in 1:n_cycle) {
p_PD_SoC[i] <- 1 - S_PD_SoC[i+1] / S_PD_SoC[i]
p_PD_Exp[i] <- 1 - S_PD_Exp[i+1] / S_PD_Exp[i]
}
# Then we generate our transition probability under standard of care and under the experimental treatement using survival functions that havent and have had the hazard ratio from above applied to them, respectively. [If we decide not to apply a hazard ratio for the experimental strategy going from progression to dead then neither may have a hazard ratio applied to them].
# The way this works is, you take next cycles probability of staying in this state, divide it by this cycles probability of staying in this state, and take it from 1 to get the probability of leaving this state.
p_PD_SoC
p_PD_Exp
# Time-constant transition probabilities [ADVERSE EVENTS]:
# To create transition probabilities from longer time periods I can use the information in this email to Daniel:
# Inquiry re: Cost effectiveness analysis of pharmacokinetically-guided 5-fluorouracil in FOLFOX chemotherapy for metastatic colorectal cancer
# - https://outlook.office.com/mail/id/AAQkAGI5OWU0NTJkLTEzMjgtNGVhOS04ZGZiLWZkOGU1MDg3ZmE5MAAQAHQCBS2m%2B%2FVAjAc%2FWSCjQEQ%3D
# There may also be some relevant information in the below:
## Transition probabilities and hazard ratios
# "Note: To calculate the probability of dying from S1 and S2, use the hazard ratios provided. To do so, first convert the probability of dying from healthy, p_HD , to a rate; then multiply this rate by the appropriate hazard ratio; finally, convert this rate back to a probability. Recall that you can convert between rates and probabilities using the following formulas: r = − log(1 − p) and p = 1 − e ( − rt ) . The package darthtools also has the functions prob_to_rate and rate_to_prob that might be of use to you." per: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop _ DARTH\August_25\3_cSTM - history dependence_material\Download exercise handout
# ?rate_to_prob will tell you more about this function.
# ?prob_to_rate will tell you more about this function.
# As will the 50 minute mark of: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop _ DARTH\August_25\Live Session Recording\Live Session Recording August 25th WITH CHAT.mkv
# The above also describes how to convert probabilities for different time scales, i.e., convert a probability for 5 years to 1 year, etc., and how to convert data that exists as a rate to a probability for use in a Markov model.
# The intial probabilities before I decided to do parametric survival analysis:
# p_HS_SoC  <- 0.05  # probability of becoming OS when PFS, conditional on surviving, under standard of care
# p_HS_trtA <- 0.04  # probability of becoming OS when PFS, conditional on surviving, under EPI Assay
# p_HS_trtB <- 0.02  # probability of becoming OS when PFS, conditional on surviving, under HDX Assay
# p_SD      <- 0.1   # probability of dying
# p_HD      <- 0.01  # probability of dying when PFS
# H = HEALTHY (PFS) -> HS MEANS HEALTHY TO SICK, HD -> MEANS HEALTHY TO DEAD.
# S = SICK (OS) -> SD MEANS SICK TO DEAD.
# D = DEAD (DEAD)
# trtA -> Means the first intervention I am studying, i.e. treatment A or the first assay.
# trtB -> Means the second intervention I am studying, i.e. treatment B or the second assay.
# To add age specific mortality to our model, we would use this #03 input model parameters of:
# "C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Decision Modeling for Public Health_DARTH\5_Nov_29\4_Cohort state-transition models (cSTM) - time-dependent models_material\Markov_3state_time"
# with the 55 minute mark of: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop _ DARTH\August_24\Live Session Recording\Live Session Recording August 24th.mp4
# and this would allow us to create a vector of transition probabilities for p_HD above, i.e., from PFS to dead, that is a little bit larger at each cycle, starting at our chosen minimum value at the first cycle and increasing each cycle until it reaches our chosen maximum value at the last cycle.
# Alternatively, C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\Training Resources\Cost-Effectiveness and Decision Modeling using R Workshop _ DARTH\August_24\4_cSTM - time-dependent models_material shows you how to use a life-table, as does the material from the York course, but I really think there's no need to get that detailed in our own analysis.
# Now that I am doing parametric survival analysis, the only probabilities I need to generate here are the adverse event probabilities, I generate them as conditional probabilities per chunk 20:
# Probability of going to the adverse event state from the progression free state:
p_FA1_STD     <- 0.02   # probability of adverse event 1 when progression-free under SOC
p_A1_D_STD    <- 0.1    # probability of dying when in adverse event 1 under SOC
p_FA2_STD     <- 0.02   # probability of adverse event 2 when progression-free under SOC
p_A2_D_STD    <- 0.1    # probability of dying when in adverse event 2 under SOC
p_FA3_STD     <- 0.02   # probability of adverse event 3 when progression-free under SOC
p_A3_D_STD    <- 0.1    # probability of dying when in adverse event 3 under SOC
p_FA1_EXPR     <- 0.02   # probability of adverse event 1 when progression-free under EXPR
p_A1_D_EXPR    <- 0.1    # probability of dying when in adverse event 1 under EXPR
p_FA2_EXPR     <- 0.02   # probability of adverse event 2 when progression-free under EXPR
p_A2_D_EXPR    <- 0.1    # probability of dying when in adverse event 2 under EXPR
p_FA3_EXPR     <- 0.02   # probability of adverse event 3 when progression-free under EXPR
p_A3_D_EXPR    <- 0.1    # probability of dying when in adverse event 3 under EXPR
p_PD_SoC
p_PD_Exp
p_FP_SoC
p_FP_Exp
p_FD_SoC   <- 0.02 # Probability of dying when progression-free:
p_FD_Exp   <- 0.02 # Probability of dying when progression-free:
# When digitising a progression-free survival curve everyone on that curve is on PFS, and if they leave that curve it is because their disease has progressed (so they've gone from progression free to progression, or from PFS to OS) or they've died:
# "Progression-free survival (PFS) is defined as the time from random assignment in a clinical trial to disease progression or death from any cause." https://www.ncbi.nlm.nih.gov/books/NBK137763/
# "Progression-free survival (PFS) is "the length of time during and after the treatment of a disease, such as cancer, that a patient lives with the disease but it does not get worse". https://en.wikipedia.org/wiki/Progression-free_survival#:~:text=Progression-free%20survival%20(PFS),it%20does%20not%20get%20worse".
# Time to Progression:
# "The length of time from the date of diagnosis or the start of treatment for a disease until the disease starts to get worse or spread to other parts of the body. In a clinical trial, measuring the time to progression is one way to see how well a new treatment works. Also called TTP." https://www.cancer.gov/publications/dictionaries/cancer-terms/def/time-to-progression
# Koen's data is time to progression data, so we can't figure out time to death from it. It may be possible to do this with the data I end up using, or as advised by the C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\R Code\Parametric Survival Analysis\flexsurv folder, but at the moment I'll just set PFS to Dead as a time-constant transition probability as he does.
# I could probably apply parametric survival models to OS data, as all individuals from the OS curve were under standard of care, and get free to dead that way from the data.
# PFS -> PFS:
p_PFS_SoC  <-   (1 - p_FD_SoC) * (1 - p_FP_SoC)
p_PFS_Exp  <-   (1 - p_FD_Exp) * (1 - p_FP_Exp)
# First, I need to create progression free survival probabilities under standard of care.
# It's 1- p_FD_SoC, because if you're not going from healthy to dead then you're staying in healthy (i.e. you're not going from PFS to Dead, so you're staying in PFS) so this captures all the people leftover in PFS after those going to dead, and again for 1- p_FP_SoC, if you're not going from healthy to sick, the only other way out of healthy per the transition probability matrix, then you're staying in PFS, so 1- p_FP_SoC takes away all the people who went from healthy to sick, and leaves behind all the people who stayed in healthy (or takes away all the people who went to OS and leaves behind all the people that went to PFS per my model).
# PFS -> OS:
p_PFS_OS_SoC    <- (1 - p_FD_SoC) *      p_FP_SoC
p_PFS_OS_Exp    <- (1 - p_FD_Exp) *      p_FP_Exp
# We have to get the probability for going from PFS to OS, by getting all the people left in PFS after the people who went to death were gone, and then we multiply this probability by the probability of going from healthy to sick, or PFS to OS, because it's the probability conditional on being alive, the probability conditional on being left in the PFS state after the other people who went to the death state are gone, so the probability of going from PFS to OS, conditional on surviving.
# p_PFS_OS_SoC is the probability of transitioning from healthy to sick, conditional on surviving, so it's defined as a conditional probability. So, what the Markov model wants is : m_P_SoC["PFS", "OS"] what's the overall probability of transitioning from PFS to OS, and so that is actually not a conditional probability, which is why we multiply the probability of surviving (1 - p_HD) *      p_HS_SoC by the probability of going to OS conditional on surviving, because the transition in the model should be the marginal not the conditional, i.e. you want to have the end probability.
#So, because you took a probability that was conditional from the literature, or digitised a PFS curve to get a transition probability - and those probabilities come from people who were necessarily still in the PFS state when you digitise a PFS curve, so those are transition probabilities conditional on being in the PFS (or healthy) state - you need to do the multiplication to give you a probability you can put in your transition matrix that reflects that the probability you are working with is conditional.
# Adverse event transition probabilities have all been conditional, this is to reflect that probabilities on transitioning from adverse event to death will necessarily be conditional probabilities - as they come from individuals who were studied in the adverse event group - so they are necessarily probabilities conditional on experiencing the adverse event. Likewise, the probability of experiencing the adverse event when under treatment is conditional on being in PFS for the treatment in the first place, because it will come from reports of adverse events in studies of the treatments given that we look at.
# Which means conditional probabilities kind of don't matter too much, because the probability won't be applied to anyone who isnt in the state it doesnt necessarily need to be conditional after all. And I guess it would have never been applied to anyone who wasnt in the state, because probabilities are only applied to people who are in the state when the transition probability matrix is multiplied by the cohort trace of people in the state.
p_FA1_SoC  <- (p_PFS_SoC) * p_FA1_STD
# Probability of AE1 when PFS, conditional on surviving, under standard of care
p_A1D_SoC  <- 0.001
# Probability of going from AE1 to death, at the moment this is just a dummy value, I expect this to be a really low value source from the literature.
p_A1F_SoC  <- 1-p_A1D_SoC
# Probability of returning from AE1 to PFS is 100% minus the people who have gone into the dead state.
# I repeat this for the other adverse events and for both standard of care and the experimental (novel) treatment:
# Probability of A2 when PFS, conditional on surviving, under standard of care
p_FA2_SoC  <- (p_PFS_SoC) * p_FA2_STD
# Probability of going from A2 to death, at the moment this is just a dummy value, I expect this to be a really low value source from the literature.
p_A2D_SoC  <- 0.001
# Probability of returning from A2 to PFS is 100% minus the people who have gone into the dead state.
p_A2F_SoC  <- 1-p_A2D_SoC
# Probability of A3 when PFS, conditional on surviving, under standard of care
p_FA3_SoC  <- (p_PFS_SoC) * p_FA3_STD
# Probability of going from A3 to death, at the moment this is just a dummy value, I expect this to be a really low value source from the literature.
p_A3D_SoC  <- 0.001
# Probability of returning from A3 to PFS is 100% minus the people who have gone into the dead state.
p_A3F_SoC  <- 1-p_A3D_SoC
# Probability of A1 when PFS, conditional on surviving, under standard of care
p_FA1_Exp  <- (p_PFS_Exp) * p_FA1_EXPR
# Probability of going from A1 to death, at the moment this is just a dummy value, I expect this to be a really low value source from the literature.
p_A1D_Exp  <- 0.001
# Probability of returning from A1 to PFS is 100% minus the people who have gone into the dead state.
p_A1F_Exp  <- 1-p_A1D_Exp
# Probability of A2 when PFS, conditional on surviving, under standard of care
p_FA2_Exp  <- (p_PFS_Exp) * p_FA2_EXPR
# Probability of going from A2 to death, at the moment this is just a dummy value, I expect this to be a really low value source from the literature.
p_A2D_Exp  <- 0.001
# Probability of returning from A2 to PFS is 100% minus the people who have gone into the dead state.
p_A2F_Exp  <- 1-p_A2D_Exp
# Probability of A3 when PFS, conditional on surviving, under standard of care
p_FA3_Exp  <- (p_PFS_Exp) * p_FA3_EXPR
# Probability of going from A3 to death, at the moment this is just a dummy value, I expect this to be a really low value source from the literature.
p_A3D_Exp  <- 0.001
# Probability of returning from A3 to PFS is 100% minus the people who have gone into the dead state.
p_A3F_Exp  <- 1-p_A3D_Exp
# These all have to be conditional on survival, i.e. conditional on being in PFS, this is to ensure that I am only applying adverse events to the people still in the PFS, after transitions etc., have happened. --> This is not how conditional probabilities work, I have the correct interpretation of them elsewhere in this code file.
## Health State Values (AKA State rewards)
# Costs and utilities
# Basically the outcomes we are interested in coming out of this model, so we'll look at the cohorts costs over the time horizon and the quality adjusted life years in our cohort over this time horizon.
# Costs
c_F_SoC       <- 400   # cost of one cycle in PFS state under standard of care
c_F_Exp       <- 1000  # cost of one cycle in PFS state under the experimental treatment
c_F_Ex_trtA       <- 1000  # cost of one cycle in PFS state under the experimental treatment A
c_F_Ex_trtB       <- 1000  # cost of one cycle in PFS state under the experimental treatment
c_P       <- 1000  # cost of one cycle in progression state (I assume in OS everyone gets the same treatment so it costs everyone the same to be treated).
c_D       <- 0     # cost of one cycle in dead state
# We define the costs of the adverse events:
c_AE1 <- 100
c_AE2 <- 100
c_AE3 <- 100
# Above is the cost for each state, PFS, OS and dead,
# c_trtA    <- 800   # cost of EPI Assay in PFS state (ONCE OFF COST)
# c_trtB    <- 1500  # cost of HDX Assay in PFS state (ONCE OFF COST)
#
# # We make the cost of the assays above so that when we have treatment strategies we can add this cost of treatment to anyone whose being treated when they receive the treatment.
# Then we define the utilities per health states.
u_F       <- 0.8     # utility when PFS
u_P       <- 0.5   # utility when OS
u_D       <- 0     # utility when dead
# We define the utilities in the adverse event states:
u_AE1 <- 0.5
u_AE2 <- 0.5
u_AE3 <- 0.5
# Discounting factors
d_c             <- 0.04
# discount rate for costs (per year)
d_e             <- 0.04
# discount rate for QALYs (per year)
# discount rate per cycle equal discount of costs and QALYs by 4%
# Discount weight (equal discounting is assumed for costs and effects)
# Actually I've updated this and do this later on now
# v_dwc <- 1 / (1 + d_c) ^ (0:n_cycle)
# v_dwe <- 1 / (1 + d_e) ^ (0:n_cycle)
# So, we create a discount weight vector above, to understand the way this works I'll have to return to my York notes on discounting
# WHEN COMING BACK TO COMPARE: C:\Users\Jonathan\OneDrive - Royal College of Surgeons in Ireland\COLOSSUS\R Code\Parametric Survival Analysis\ISPOR WEBINAR Health Economic Modelling in R\ISPOR_webinar_R-master\ISPOR_webinar_R-master\oncologySemiMarkov_illustration to this Rmarkdown document, a big difference is that this document creates a cycle 0 - whereas the comparison from the ISPOR_webinar_R uses -1 to get into cycle 0 where necessary. I have decided to follow the ISPOR way, because I am interested in duplicating their parametric analysis, so I need to bear this difference in mind as I go through this document.
# Also, continue from Verbose in this and in Koens file
# Markov cohort trace matrix ----
# Initialize matrices to store the Markov cohort traces for each strategy
# - note that the number of rows is n_cycle + 1, because R doesn't use index 0 (i.e. cycle 0)  --> What we mean here, is that when we do our calculations later they need to be for cycle-1 to reflect cycle 0.
m_M_SoC <- m_M_Exp  <-  matrix(
data = NA,
nrow = n_cycle,
ncol = n_states,
dimnames = list(paste('Cycle', 1:n_cycle), v_names_states)
)
## Initial state vector
# We create an inital vector where people start, with everyone (1 = 100% of people) starting in PFS below:
# v_s_init <- c("PFS" = 1, "OS" = 0, "Dead" = 0)
# v_s_init
# There are cases where you can have an initial illness prevalence, so you would start some people in the sick state and some people in the healthy state, but above we're looking at people with mCRC, so we'll start everyone in PFS.
## Initialize cohort trace for cSTM (cohort state transition model) for all strategies (the strategies are the treatment strategies SOC, treatment A and Treatment B).
# So, basically we are creating a matrix to trace how the cohort is distributed across the health states, over time.
# A matrix is necessary because there are basically two dimensions to this, the number of time cycles, which will be our rows, and then the number of states - to know which proportion of our cohort is in each state at each time:
# m_M_SoC <- matrix(0,
#                   nrow = (n_cycles + 1), ncol = n_states,
#                   dimnames = list(v_names_cycles, v_names_states))
# Above instead of having to bother with -1 throughout the analysis they create a cycle 0.
# Store the initial state vector in the first row of the cohort trace
# m_M_SoC[1, ] <- v_s_init
## Initialize cohort traces
## So, above I made the cohort trace for standard of care, because in my analysis all my patients start in the PFS state, I can duplicate that below to create the cohort trace for treatment A and treatment B.
# m_M_trtA <- m_M_trtB <- m_M_SoC # structure and initial states remain the same
# This gives us three matrices, m_M_trtA, m_M_trtB and m_M_SoC, that we can fill in with our simulations of how patients transitions between health states under each treatment strategy.
# In the first row of the markov matrix [1, ] put the value at the far end, i.e. "<-1" and "<-0" under the colum "PFS" [ , "PFS"], repeating this for "OS", "AE1", "AE2" "AE3" and "Dead".
# Specifying the initial state for the cohorts (all patients start in PFS)
m_M_SoC[1, "PFS"] <- m_M_Exp[1, "PFS"] <- 1
m_M_SoC[1, "AE1"] <- m_M_Exp[1, "AE1"] <- 0
m_M_SoC[1, "AE2"] <- m_M_Exp[1, "AE2"] <- 0
m_M_SoC[1, "AE3"] <- m_M_Exp[1, "AE3"] <- 0
m_M_SoC[1, "OS"]  <- m_M_Exp[1, "OS"]  <- 0
m_M_SoC[1, "Dead"]<- m_M_Exp[1, "Dead"]  <- 0
# Inspect whether properly defined
head(m_M_SoC)
head(m_M_Exp)
#head(m_M_Exp_trtB)
# for (t in 1:n_cycles){  # Use a for loop to loop through the number of cycles, basically we'll calculate the cohort distribution at the next cycle [t+1] based on the matrix of where they were at time t, matrix multiplied by the transition probability matrix for the current cycle (constant for us as we use a constant transition probability matrix, rather than a transition probability array).
# We do this for each treatment, as they all have different transition probability matrices.
#  m_M_SoC [t + 1, ] <- m_M_SoC [t, ] %*% m_P_SoC   # estimate the state vector for the next cycle (t + 1)
#  m_M_trtA[t + 1, ] <- m_M_trtA[t, ] %*% m_P_trtA  # estimate the state vector for the next cycle (t + 1)
#  m_M_trtB[t + 1, ] <- m_M_trtB[t, ] %*% m_P_trtB  # estimate the state vector for the next cycle (t + 1)
# }
# head(m_M_SoC)  # print the first few lines of the matrix for standard of care (m_M_SoC)
# Above I was originally using a transition probability matrix, because I was using a time constant transition probability. But now, because my transition probabilities come from the survival curves, and thus change over time, I am using a transition probability array.
# Thus, I adapt the above to reflect that my transition probability selected has to come from a certain cycle, i.e. from a certain time, and then be multiplied by the number of people in the matrix, the amount of the cohort in the matrix, at that cycle, i.e. at that time. Thats why below I pick the third dimension of the array, not row, not column, but time: R,C,T i.e.   ->  , ,i_cycle
# So here I once again create the Markov cohort trace by looping over all cycles
# - note that the trace can easily be obtained using matrix multiplications
# - note that now the right probabilities for the cycle need to be selected, like I explained above.
for(i_cycle in 1:(n_cycle-1)) {
m_M_SoC[i_cycle + 1, ] <- m_M_SoC[i_cycle, ] %*% m_P_SoC[ , , i_cycle]
m_M_Exp[i_cycle + 1, ] <- m_M_Exp[i_cycle, ] %*% m_P_Exp[ , , i_cycle]
}
#                   nrow = (n_cycles + 1), ncol = n_states,
#                   dimnames = list(v_names_cycles, v_names_states))
# Above instead of having to bother with -1 throughout the analysis they create a cycle 0.
# Store the initial state vector in the first row of the cohort trace
#
# Specifying the initial state for the cohorts (all patients start in PFS)
m_M_SoC[1, "PFS"] <- m_M_Exp[1, "PFS"] <- 1
